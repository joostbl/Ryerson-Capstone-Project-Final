---
title: "Sentiment Analysis FINAL"
author: "Joost Bloos"
date: "07/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Install packages:
#Source: https://trinkerrstuff.wordpress.com/my-r-packages/qdap/

#if (!require("pacman")) install.packages("pacman")
#pacman::p_load(sentimentr, dplyr, magrittr)
#install.packages("devtools")
#install_github("trinker/qdapDictionaries")
#install_github("trinker/qdapRegex")
#install_github("trinker/qdapTools")
#install_github("trinker/qdap")
#install.packages("quanteda")
#install.packages("sentimentr")
#install.packages("ndjson")
#install.packages("NLP")
#install.packages("dplyr")
#install.packages("tidyr")
#install.packages("tm")
#install.packages("corpus")
#install.packages("syuzhet")
#install.packages("plotly")
#install.packages("wordcloud")

```


```{r}
library(devtools)
library(tm)
library(qdap)
library(sentimentr)
library(ndjson)
library(corpus)
library(syuzhet)
library(tidyr)
library(dplyr)
library(quanteda)
library(ggplot2)
library(plotly)
library(wordcloud)
library(profmem)

#a good package, also takes into account  negative words and amplifiers
#see: http://www.inside-r.org/packages/cran/qdap/docs/polarity
```

```{r}
#getwd()
#setwd("C:/Ryerson University - Capstone project/Module 2/EIEEE - Large dataset/Combined")
```


```{r}
rawData100K <- read.csv(file = "rawData100K.csv")

str(rawData100K)
```

```{r}
#create a corpus:
importdocs = corpus(rawData100K, text_field = 'text')

```

```{r}
#preprocessing of data
importdocs <- gsub("'", "", importdocs)  # remove apostrophes
importdocs <- gsub("[[:punct:]]", " ", importdocs)  # replace punctuation with space
importdocs <- gsub("[[:cntrl:]]", " ", importdocs)  # replace control characters with space
importdocs <- gsub("^[[:space:]]+", "", importdocs) # remove whitespace at beginning of documents
importdocs <- gsub("[[:space:]]+$", "", importdocs) # remove whitespace at end of documents
importdocs <- tolower(importdocs)

# CLEANING TWEETS
importdocs=gsub("&amp", "", importdocs)
importdocs = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", importdocs)
importdocs = gsub("@\\w+", "", importdocs)
importdocs = gsub("[[:digit:]]", "", importdocs)
importdocs = gsub("http\\w+", "", importdocs)
importdocs = gsub("[ \t]{2,}", "", importdocs)
importdocs = gsub("^\\s+|\\s+$", "", importdocs)
importdocs <- iconv(importdocs, "UTF-8", "ASCII", sub="")

head(importdocs)
```


```{r}
#keep getting an error message recommending to run the raw 'character' vector through get_sentences function.

mycorpus <- get_sentences(importdocs)

```

```{r}
#apply sentimentr package #Measure running time and memory

start_time <- Sys.time()
mysentiment_memory <- profmem({
  sentiment(mycorpus)
})
end_time <- Sys.time()

end_time - start_time
#print(mysentiment_memory, expr = FALSE)

#Giga Bytes used:
sum((mysentiment_memory$bytes), na.rm=TRUE)/1000000000 

```


```{r}
#apply sentimentr package 
mysentiment <- sentiment(mycorpus)

```


```{r}
# run overall score, result overall neutral to perhaps moderate positive
summary(mysentiment$sentiment)
```

```{r}
#results expressed in histogram

qplot(mysentiment$sentiment,   geom="histogram",binwidth=0.1,main="Review Sentiment Histogram")
```

```{r}
#source: https://www.programmingr.com/sentiment-analysis/

#returns the individual words along with their polarity strength and counts.
t = extract_sentiment_terms(mycorpus) 
attributes(t)$count
```

```{r}
#show positive and negative word use:
head(t,20)
```

```{r}
# The emotion() function returns the rate of emotion per sentence. A data frame is returned by this function and of interest to us are the two columns: emotion type and emotion. Emotion indicates the strength of emotion present in the sentence.
emotion(mycorpus[1:2])
```

```{r}
#integrate sentiment score into updated dataset
#sentimentResultMay2020 <- rawData100K
#sentimentResultMay2020$sentiment_score = mysentiment$sentiment
#str(sentimentResultMay2020)
```

```{r}
#identify text for max (positive) sentiment score
#max(mysentiment$sentiment)
#maxSentiment <- sentimentResultMay2020[which.max(sentimentResultMay2020$sentiment_score),]
#maxSentiment$text
```

```{r}
#identify text for min sentiment score
#min(mysentiment$sentiment)
#minSentiment <- sentimentResultMay2020[which.min(sentimentResultMay2020$sentiment_score),]
#minSentiment$text
```

```{r}
#write sentiment score to original dataset
#write.csv(sentimentResultMay2020,'sentimentResultMay2020.csv')
```


